{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade --quiet  langchain langchain-openai\n",
    "#%pip install pypdf\n",
    "#%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habte/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/habte/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "#File paths for the PDF documents\n",
    "pdf_paths = [\n",
    "    \"/home/habte/Downloads/Raptor Contract.docx.pdf\",\n",
    "    \"/home/habte/Downloads/Raptor Q&A2.docx.pdf\",\n",
    "    \"/home/habte/Downloads/Robinson Advisory.docx.pdf\",\n",
    "    \"/home/habte/Downloads/Robinson Q&A.docx.pdf\"\n",
    "    ]\n",
    "\n",
    "# Load PDF and split into tokens for all documents\n",
    "pdf_data = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    pdf_data.extend(loader.load())\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_data = text_splitter.split_documents(pdf_data)\n",
    "\n",
    "# Set up ChromaDB with vector embeddings\n",
    "collection_name = \"contracts_collection\"\n",
    "local_directory = \"contracts_vect_embedding\"\n",
    "persist_directory = os.path.join(os.getcwd(), local_directory)\n",
    "\n",
    "openai_key = os.environ.get('OPENAI_API_KEY')  # Use a proper environment variable name\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "vect_db = Chroma.from_documents(\n",
    "    split_data,\n",
    "    embeddings,\n",
    "    collection_name=collection_name,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "vect_db.persist()\n",
    "\n",
    "# Initialize the OpenAI language model\n",
    "chat_model = ChatOpenAI(openai_api_key=openai_key, model_name=\"gpt-3.5-turbo\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "chat_qa = ConversationalRetrievalChain.from_llm(\n",
    "    chat_model,\n",
    "    vect_db.as_retriever(),\n",
    "    memory=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habte/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n",
      "Assistant: I don't have specific information about contracts in general. If you have a specific question about a contract or a particular type of contract, feel free to ask!\n",
      "Assistant: The provided context outlines various types of contractual obligations that the Company must disclose to the Buyer in specific schedules. These obligations include employment or consultancy agreements, distribution contracts, powers of attorney, lease agreements, loans to affiliates, and agreements with related parties. The Company must ensure that these contracts are enforceable, not in breach, and will continue to be enforceable after the transaction. The Company is also required to disclose any related party transactions and ensure that employees have the necessary permits and classifications. Additionally, the Company should not have any outstanding payments or disputes with current or former employees, directors, or other service providers.\n",
      "Assistant: Contractual obligations that a company must disclose to a buyer in specific schedules include obligations related to employment or consultancy agreements with officers or directors, agency agreements, powers of attorney, agreements with affiliates, collective bargaining agreements with unions, and contracts with related parties. These obligations need to be accurately and completely disclosed in the relevant schedules for transparency and enforcement purposes.\n"
     ]
    }
   ],
   "source": [
    "# Chat loop\n",
    "chat_history = []\n",
    "\n",
    "while True:\n",
    "    query = input('You: ')  # Prompt the user to input a question\n",
    "\n",
    "    if query.lower() == 'done':  # Check if the user wants to end the conversation\n",
    "        break\n",
    "\n",
    "    response = chat_qa({\"question\": query, \"chat_history\": chat_history})  # Retrieve response\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": query})  # Update chat history\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
    "\n",
    "    print('Assistant:', response[\"answer\"])  # Print the assistant's response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
